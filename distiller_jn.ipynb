{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-27 10:10:05,462 [nnabla][INFO]: Initializing CPU extension...\n"
     ]
    }
   ],
   "source": [
    "import nnabla as nn\n",
    "import numpy as np\n",
    "import nnabla.functions as F\n",
    "import nnabla.parametric_functions as PF\n",
    "from nnabla.utils.data_iterator import data_iterator\n",
    "from nnabla.utils.data_source import DataSource\n",
    "import nnabla.utils.learning_rate_scheduler as lr_scheduler\n",
    "from scheduler import *\n",
    "import nnabla.solvers as S\n",
    "from collections import OrderedDict\n",
    "\n",
    "import utils_functions as UF\n",
    "from data import *\n",
    "from loss import *\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from nnabla.models.imagenet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(f):\n",
    "    if f.name=='BatchNormalization':\n",
    "        \"\"\"\n",
    "        f.inputs = [\n",
    "            input feature,\n",
    "            gamma of bn,\n",
    "            beta of bn,\n",
    "            running_mean,\n",
    "            running_std\n",
    "        ]\n",
    "        \"\"\"\n",
    "        stat = {}\n",
    "        outs.append(f.inputs[0])\n",
    "        stat['running_mean'] = nn.Variable.from_numpy_array(f.inputs[3].d, need_grad=False)\n",
    "        stat['running_std'] = nn.Variable.from_numpy_array((f.inputs[4].d + 1e-6)**0.5, need_grad=False) \n",
    "        batch_stats.append(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_distill(model, uniform_data_iterator, num_iter):\n",
    "    generated_img = []\n",
    "    for _ in range(uniform_data_iterator.size // uniform_data_iterator.batch_size):\n",
    "        img, _ = uniform_data_iterator.next()\n",
    "        dst_img = nn.Variable(img.shape, need_grad=True)\n",
    "        dst_img.d = img\n",
    "        img_params = OrderedDict()\n",
    "        img_params['img'] = dst_img\n",
    "\n",
    "        solver = S.Adam(alpha=0.5)\n",
    "        solver.set_parameters(img_params)\n",
    "        #scheduler = lr_scheduler.CosineScheduler(init_lr=0.5, max_iter=num_iter)\n",
    "        scheduler = ReduceLROnPlateauScheduler(init_lr=0.5, min_lr=1e-4, verbose=False, patience=100)\n",
    "        dummy_solver = S.Sgd(lr=0)\n",
    "        dummy_solver.set_parameters(nn.get_parameters())\n",
    "\n",
    "        for it in tqdm(range(num_iter)):\n",
    "            lr = scheduler.get_learning_rate()\n",
    "            solver.set_learning_rate(lr)\n",
    "\n",
    "            global outs\n",
    "            outs = []\n",
    "            global batch_stats\n",
    "            batch_stats = []\n",
    "\n",
    "            y = model(dst_img, force_global_pooling=True, training=False)\n",
    "            y.forward(function_post_hook=get_output)\n",
    "            assert len(outs) == len(batch_stats)\n",
    "            loss = zeroq_loss(batch_stats, outs, dst_img)\n",
    "            loss.forward()\n",
    "            solver.zero_grad()\n",
    "            dummy_solver.zero_grad()\n",
    "            loss.backward()\n",
    "            solver.weight_decay(1e-6)\n",
    "            solver.update()\n",
    "\n",
    "            scheduler.update_lr(loss.d)\n",
    "\n",
    "        generated_img.append(dst_img.d)\n",
    "\n",
    "    return generated_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_img(generated_img, save_path):\n",
    "    for index, batch_img in enumerate(generated_img):\n",
    "        bsize = batch_img.shape[0]\n",
    "        for i in range(bsize):\n",
    "            img = batch_img[i].transpose((1,2,0))\n",
    "            img = np.clip(img * np.sqrt(5418.75) + 127.5, 0, 254).astype(np.uint8)\n",
    "            cv2.imwrite(f'{save_path}/{index*bsize+i}.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-27 10:10:13,268 [nnabla][INFO]: Downloading Resnet-18.nnp from https://nnabla.org/pretrained-models/nnp_models/imagenet/Resnet-18/Resnet-18.nnp\n",
      "2020-08-27 10:10:13,270 [nnabla][INFO]: > /Users/hiromichikamata/nnabla_data/nnp_models/imagenet/Resnet-18.nnp already exists.\n",
      "2020-08-27 10:10:13,274 [nnabla][INFO]: > If you have any issue when using this file, \n",
      "2020-08-27 10:10:13,280 [nnabla][INFO]: > manually remove the file and try download again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /Users/hiromichikamata/nnabla_data/nnp_models/imagenet/Resnet-18.nnp.\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 224, 224)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._input_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 17:29:16,373 [nnabla][INFO]: DataSource with shuffle(True)\n",
      "2020-08-26 17:29:16,388 [nnabla][INFO]: Using DataIterator\n"
     ]
    }
   ],
   "source": [
    "data_length = 2\n",
    "uniform_data_source = UniformData(length=data_length, train=True, shuffle=True, rng=None)\n",
    "bsize = 2\n",
    "uniform_data_iterator = data_iterator(uniform_data_source, \n",
    "                                    batch_size=bsize, \n",
    "                                    rng=None, \n",
    "                                    with_memory_cache=False,\n",
    "                                    with_file_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "generated_img = data_distill(model, uniform_data_iterator, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
